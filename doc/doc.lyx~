#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\date {}

\usepackage{titling}
\setlength{\droptitle}{-4em}
\posttitle{\par\end{center}\vspace{-1em}}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language brazilian
\language_package auto
\inputencoding auto
\fontencoding global
\font_roman "default" "Ubuntu Mono"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "default"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize 11
\spacing onehalf
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation 1.25cm
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Trabalho Prático 2 - Q-Learning
\begin_inset Newline newline
\end_inset

Inteligência Artificial 2019/1
\end_layout

\begin_layout Author
Gabriel Henrique Souto Pires - 2014106384
\end_layout

\begin_layout Section
Implementação
\end_layout

\begin_layout Standard
Este projeto foi implementado na linguagem Python versão 3.6.7 e testado em
 ambiente Linux versão Ubuntu 18.04.2 LTS.
 Foram criadas 2 classes, sendo uma para o tabuleiro e outra para o algoritmo
 de Q-Learning.
 Em um terceiro arquivo, os argumentos de execução são recebidos e os algoritmos
 executados.
\end_layout

\begin_layout Subsection
Decisões de Projeto
\end_layout

\begin_layout Standard
Ao receber os argumentos, é criado um objeto da classe 
\emph on
Maze
\emph default
 que lê o arquivo contendo o labirinto e joga os caracteres que o compõem
 em uma matriz 
\begin_inset Formula $n\times m$
\end_inset

 sendo 
\begin_inset Formula $n$
\end_inset

 o número de linhas e 
\begin_inset Formula $m$
\end_inset

 o número de colunas do labirinto, ambas as dimensões também são passadas
 no arquivo de entrada.
 A classe 
\emph on
Maze
\emph default
 também tem um método que retorna uma posição aleatória válida no labirinto,
 ou seja, uma posição aleatória em que o pacman pode ficar, isso será útil
 mais tarde na hora de rodar o algoritmo de q-learning, uma vez que a posição
 inicial do pacman no labirinto é sempre aleatória.
 Existe também um método para mostrar o labirinto na tela, mas esse método
 foi utilizado apenas para fins de debug.
\end_layout

\begin_layout Standard
Na classe referente ao algoritmo de q-learning, primeiro guardamos os argumentos
 
\begin_inset Formula $\alpha$
\end_inset

, 
\begin_inset Formula $\varepsilon$
\end_inset

 e 
\begin_inset Formula $n$
\end_inset

 que são a taxa de aprendizado, o fator de exploração da estratégia ε-greedy
 e a quantidade de episódios que serão executados respectivamente, também
 é passado o labirinto lido anteriormente e uma posição aleatória é atribuída
 ao estado inicial pelo método 
\emph on
random_valid_positon
\emph default
()
\emph on
 
\emph default
da classe 
\emph on
Maze
\emph default
.
 
\end_layout

\begin_layout Standard
Para criar a q-table, foi escolhido usar um dicionário ao invés de uma simples
 matriz com cada valor, o que tornou o processo de atualização da q-table
 muito mais rápido, aumentando a velocidade de execução do programa, uma
 vez que para se acessar uma posição específica usando um dicionário, isso
 é feito em 
\begin_inset Formula $O(1)$
\end_inset

, ao contrário da matriz que, para cada estado, seria necessário percorrer
 o vetor de ações até se encontrar qual deveria ser atualizada.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename dict.png
	width 80line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Estrutura da q-table.
 As primeiras chaves correspondem à linha em que cada estado se encontra,
 as chaves dentro dessa primeira correspondem à posição da coluna de cada
 estado, dentro dessa segunda chave ficam os pares de ação e recompensa
 de cada estado.
 Dessa forma é possível atualizar um valor na q-table em O(1), uma vez que
 cada estado e cada ação tem um índice que pode ser acessado diretamente.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Apesar de ser mais eficiente, o formato de saída do programa não é em forma
 de dicionário, então foi criada um método para formatar a q-table do jeito
 que foi pedido para o arquivo de saída.
 Como pode ser visto abaixo:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
1,1,R,6.165 
\end_layout

\begin_layout Plain Layout
1,1,L,4.481 
\end_layout

\begin_layout Plain Layout
1,1,U,4.379 
\end_layout

\begin_layout Plain Layout
1,1,D,2.929 
\end_layout

\begin_layout Plain Layout
1,2,R,7.991 
\end_layout

\begin_layout Plain Layout
1,2,L,4.505 
\end_layout

\begin_layout Plain Layout
1,2,U,6.118
\end_layout

\begin_layout Plain Layout
....
 (demais pares estado-ação)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Cada tipo de estado do labirinto tem um valor de recompensa pré-definido,
 sendo que estados representados por '-' tem valor 
\begin_inset Formula $-1$
\end_inset

, estados representados por '0' tem valor 
\begin_inset Formula $10$
\end_inset

 e estados representados por '&' tem valor 
\begin_inset Formula $-10$
\end_inset

.
 Os estados representados por '#' não tem valor de recompensa, uma vez que
 não é possível andar sobre eles.
\end_layout

\begin_layout Standard
Para cada movimento do pacman, a q-table é atualizada seguindo a seguinte
 fórmula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Q[state,action]=Q[state,action]+alpha*(reward+gamma*max(Q[new\_state,actions])\text{—}Q[state,action]
\]

\end_inset


\end_layout

\begin_layout Standard
onde 
\begin_inset Formula $reward$
\end_inset

 é a recompensa do estado para o qual se está tentando ir, 
\begin_inset Formula $max(Q[new\_state,actions])$
\end_inset

 é a recompensa máxima do próximo estado e 
\begin_inset Formula $Q[state,action]$
\end_inset

 é a recompensa do estado em que o pacman está atualmente.
 Obviamente a fórmula acima é apenas uma abstração, no código são usadas
 outras estruturas e funções que não cabe mostrar aqui.
\end_layout

\begin_layout Standard
Após se atualizar a q-table, é testado se o pacman se encontra em um estado
 final (0 ou &), em caso positivo, o episódio atual é dado como terminado
 e o pacman é colocado de volta no labirinto em uma nova posição aleatória.
 Isso é feito 
\begin_inset Formula $n$
\end_inset

 vezes até que o número de episódios passados como argumento sejam concluídos.
\end_layout

\begin_layout Standard
Para se controlar a taxa de exploration e exploitation, foi usada a estratégia
 ε-greedy, que consiste em fixar um número 
\begin_inset Formula $ε$
\end_inset

 de 0 a 1 que representa a probabilidade de se executar movimentos aleatórios.
 Geramos então um número aleatório no mesmo intervalo, toda vez que o pacman
 for realizar um movimento no labirinto, se esse número for menor que o
 nosso epsilon, o pacman irá explorar o ambiente, realizando um movimento
 aleatório, se o número gerado for maior que o epsilon, o pacman ira escolher
 a direção que tem maior recompensa, daí o nome ε-greedy.
\end_layout

\begin_layout Standard
No final da execução de todos os episódios, podemos usar a q-table para
 gerar uma política, que consiste em um mapa com a ação ideal que o pacman
 deve executar a partir de cada estado, baseado nas recompensas a partir
 de cada um.
 Vamos ver as políticas geradas para cada caso de teste a seguir.
\end_layout

\begin_layout Section
Saídas obtida
\end_layout

\begin_layout Subsection
Caso 1 - Labirinto 5 por 6
\end_layout

\begin_layout Standard
Esse caso teste foi incluído junto à especificação do trabalho e serviu
 de base até que outros testes fossem disponibilizados.
 É um caso bem simples que contém apenas um estado final bom e um ruim.
\end_layout

\begin_layout Subsubsection
Entrada
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
5 6 
\end_layout

\begin_layout Plain Layout
###### 
\end_layout

\begin_layout Plain Layout
#---0# 
\end_layout

\begin_layout Plain Layout
#-#-&# 
\end_layout

\begin_layout Plain Layout
#----# 
\end_layout

\begin_layout Plain Layout
######
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Saída
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
###### 
\end_layout

\begin_layout Plain Layout
#RRR0# 
\end_layout

\begin_layout Plain Layout
#U#U&# 
\end_layout

\begin_layout Plain Layout
#URUL# 
\end_layout

\begin_layout Plain Layout
######
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Neste caso, notamos que a taxa de aprendizado é mais importante que a quantidade
 de exploitation ou exploration que o agente realiza, como fica evidente
 no gráfico abaixo.
 As 3 linhas que mais demoram a convergir são justamente aquelas em que
 o valor de 
\begin_inset Formula $\alpha$
\end_inset

 foi colocado em 
\begin_inset Formula $0.1$
\end_inset

, pouco importando o valor de 
\begin_inset Formula $\varepsilon$
\end_inset

, apesar de ficar evidente que nesse caso realizar menos exploração é mais
 vantajoso.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename grafico1.pdf
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Recompensas médias ao longo do tempo no labirinto de tamanho 5x6
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Caso 2 - Labirinto 7 por 14
\end_layout

\begin_layout Subsubsection
Entrada
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
7 14 
\end_layout

\begin_layout Plain Layout
############## 
\end_layout

\begin_layout Plain Layout
#-----0------# 
\end_layout

\begin_layout Plain Layout
#######-##-#-# 
\end_layout

\begin_layout Plain Layout
#-------&--#-# 
\end_layout

\begin_layout Plain Layout
#-##########&# 
\end_layout

\begin_layout Plain Layout
#------------# 
\end_layout

\begin_layout Plain Layout
############## 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Saída
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
############## 
\end_layout

\begin_layout Plain Layout
#RRRRR0LLLLLL# 
\end_layout

\begin_layout Plain Layout
#######U##U#U# 
\end_layout

\begin_layout Plain Layout
#RRRRRRU&RU#U# 
\end_layout

\begin_layout Plain Layout
#U##########&# 
\end_layout

\begin_layout Plain Layout
#ULLLLLLLLLLL# 
\end_layout

\begin_layout Plain Layout
############## 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Novamente fica claro que a taxa de aprendizado é muito importante para a
 velocidade de convergência.
 Mas dessa vez podemos ver também que em casos com muita exploração (a linha
 marrom por exemplo), o valor médio das recompensas tende a cair mesmo depois
 de vários episódios passarem, isso se deve ao fato de o agente escolher
 caminhos ruins aleatoriamente, e eventualmente cair em estados finais com
 recompensas muito baixas.
 Mas à medida que o tempo passa, uma vez que a q-table é ajustada melhor,
 o agente começa a tomar caminhos melhores, evitando cair em estados que
 prejudicam a recompensa média.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename grafico2.pdf
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Recompensas médias ao longo do tempo no labirinto de tamanho 7x14
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Caso 3 - Labirinto 14 por 20
\end_layout

\begin_layout Subsubsection
Entrada
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
14 20 
\end_layout

\begin_layout Plain Layout
#################### 
\end_layout

\begin_layout Plain Layout
#--------------#---# 
\end_layout

\begin_layout Plain Layout
#---&--&--&----#---# 
\end_layout

\begin_layout Plain Layout
#--------------#-#-# 
\end_layout

\begin_layout Plain Layout
#-##############-#-# 
\end_layout

\begin_layout Plain Layout
#----------------#-# 
\end_layout

\begin_layout Plain Layout
##################-# 
\end_layout

\begin_layout Plain Layout
#--------&---------# 
\end_layout

\begin_layout Plain Layout
#-&--########---&--# 
\end_layout

\begin_layout Plain Layout
#------------------# 
\end_layout

\begin_layout Plain Layout
#-################-# 
\end_layout

\begin_layout Plain Layout
#-#-----#0#--------# 
\end_layout

\begin_layout Plain Layout
#----#----#--------# 
\end_layout

\begin_layout Plain Layout
####################
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Saída
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
#################### 
\end_layout

\begin_layout Plain Layout
#DLLLLLLLLLLLLL#RRD# 
\end_layout

\begin_layout Plain Layout
#DLL&DL&DL&DLLL#RRD# 
\end_layout

\begin_layout Plain Layout
#DLLLLLLLLLLLLL#U#D# 
\end_layout

\begin_layout Plain Layout
#D##############U#D# 
\end_layout

\begin_layout Plain Layout
#RRRRRRRRRRRRRRRU#D# 
\end_layout

\begin_layout Plain Layout
##################D# 
\end_layout

\begin_layout Plain Layout
#DLLLLLLL&RRRDLLLLL# 
\end_layout

\begin_layout Plain Layout
#D&DL########DLL&DL# 
\end_layout

\begin_layout Plain Layout
#DLLLLLLLLLLLLLLLLL# 
\end_layout

\begin_layout Plain Layout
#D################U# 
\end_layout

\begin_layout Plain Layout
#D#RRRRD#0#RRRRRRRU# 
\end_layout

\begin_layout Plain Layout
#RRRU#RRRU#RRRRRRRU# 
\end_layout

\begin_layout Plain Layout
####################
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Esse é um caso interessante, no sentido que ao invés da recompensa média
 aumentar, ela começa em zero e só cai à medida que os episódios passam.
 Isso é esperado, uma vez que, o labirinto tem apenas um estado com recompensa
 positiva, e este está em uma posição muito difícil de encontrar, além de
 ser um labirinto relativamente grande e com muitos estados finais com recompens
a negativa.
 À medida que os episódios passam, o agente só consegue encontrar estados
 finais ruins ou até mesmo explorar o labirinto sem chegar a nenhum estado
 final, o que prejudica a recompensa média.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename grafico3.pdf
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Recompensas médias ao longo do tempo no labirinto de tamanho 14x20
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Caso 4 - Labirinto 11 por 20
\end_layout

\begin_layout Subsubsection
Entrada
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
11 20 
\end_layout

\begin_layout Plain Layout
#################### 
\end_layout

\begin_layout Plain Layout
#----&--------&----# 
\end_layout

\begin_layout Plain Layout
#-&&&&&&&-&&&&&&&&-# 
\end_layout

\begin_layout Plain Layout
#-------&-&--------# 
\end_layout

\begin_layout Plain Layout
#---&---&-&---&----# 
\end_layout

\begin_layout Plain Layout
#-------&-&--------# 
\end_layout

\begin_layout Plain Layout
#-----&-----&------# 
\end_layout

\begin_layout Plain Layout
#-------&-&--------# 
\end_layout

\begin_layout Plain Layout
#---&---&-&---&----# 
\end_layout

\begin_layout Plain Layout
#-------&0&--------# 
\end_layout

\begin_layout Plain Layout
####################
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Saída
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
#################### 
\end_layout

\begin_layout Plain Layout
#DLLL&RRRDLLLL&RRRD# 
\end_layout

\begin_layout Plain Layout
#D&&&&&&&D&&&&&&&&D# 
\end_layout

\begin_layout Plain Layout
#RRRRRRD&D&DLLLLLLL# 
\end_layout

\begin_layout Plain Layout
#RRD&RRD&D&DLL&DLLL# 
\end_layout

\begin_layout Plain Layout
#RRRRRRD&D&DLLLLLLL# 
\end_layout

\begin_layout Plain Layout
#RRRRU&RRDLL&ULLLLL# 
\end_layout

\begin_layout Plain Layout
#RRRRRRU&D&ULLLLLLL# 
\end_layout

\begin_layout Plain Layout
#RRU&RRU&D&ULL&ULLL# 
\end_layout

\begin_layout Plain Layout
#RRRRRRU&0&ULLLLLLL# 
\end_layout

\begin_layout Plain Layout
#################### 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename grafico4.pdf
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Recompensas médias ao longo do tempo no labirinto de tamanho 11x20
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Principais dificuldades
\end_layout

\begin_layout Section
Referências
\end_layout

\end_body
\end_document
